{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Date   Time  1510H084 Water Level  \\\n",
      "Timestamp                                                      \n",
      "2020-01-01 00:00:00    2020/1/1  00:00                145.30   \n",
      "2020-01-01 01:00:00    2020/1/1  01:00                145.30   \n",
      "2020-01-01 02:00:00    2020/1/1  02:00                145.30   \n",
      "2020-01-01 03:00:00    2020/1/1  03:00                145.30   \n",
      "2020-01-01 04:00:00    2020/1/1  04:00                145.30   \n",
      "...                         ...    ...                   ...   \n",
      "2022-12-31 19:00:00  2022/12/31  19:00                143.63   \n",
      "2022-12-31 20:00:00  2022/12/31  20:00                143.63   \n",
      "2022-12-31 21:00:00  2022/12/31  21:00                143.63   \n",
      "2022-12-31 22:00:00  2022/12/31  22:00                143.64   \n",
      "2022-12-31 23:00:00  2022/12/31  23:00                143.63   \n",
      "\n",
      "                     1510H076 Water Level  1510H071 Water Level  \\\n",
      "Timestamp                                                         \n",
      "2020-01-01 00:00:00                  5.03                 20.58   \n",
      "2020-01-01 01:00:00                  5.11                 20.80   \n",
      "2020-01-01 02:00:00                  5.11                 20.81   \n",
      "2020-01-01 03:00:00                  5.11                 20.80   \n",
      "2020-01-01 04:00:00                  5.11                 20.79   \n",
      "...                                   ...                   ...   \n",
      "2022-12-31 19:00:00                  4.69                 19.22   \n",
      "2022-12-31 20:00:00                  4.69                 19.22   \n",
      "2022-12-31 21:00:00                  4.70                 19.21   \n",
      "2022-12-31 22:00:00                  4.70                 19.21   \n",
      "2022-12-31 23:00:00                  4.70                 19.21   \n",
      "\n",
      "                     1510H057 Water Level  19774 Rainfall  20016 Rainfall  \\\n",
      "Timestamp                                                                   \n",
      "2020-01-01 00:00:00                 88.47        0.000000            0.00   \n",
      "2020-01-01 01:00:00                 88.79        0.000000            0.00   \n",
      "2020-01-01 02:00:00                 88.78        0.000000            0.00   \n",
      "2020-01-01 03:00:00                 88.84        0.000000            0.00   \n",
      "2020-01-01 04:00:00                 88.81        0.000000            0.00   \n",
      "...                                   ...             ...             ...   \n",
      "2022-12-31 19:00:00                 88.83        0.000000            0.00   \n",
      "2022-12-31 20:00:00                 88.82        0.000000            0.00   \n",
      "2022-12-31 21:00:00                 88.80        0.515206            0.25   \n",
      "2022-12-31 22:00:00                 88.81        0.000000            0.00   \n",
      "2022-12-31 23:00:00                 88.81        0.074549            0.00   \n",
      "\n",
      "                     19606 Rainfall  19335 Rainfall  \n",
      "Timestamp                                            \n",
      "2020-01-01 00:00:00        0.000000        0.000000  \n",
      "2020-01-01 01:00:00        0.000000        0.000000  \n",
      "2020-01-01 02:00:00        0.000000        0.000000  \n",
      "2020-01-01 03:00:00        0.000000        0.000000  \n",
      "2020-01-01 04:00:00        0.000000        1.428012  \n",
      "...                             ...             ...  \n",
      "2022-12-31 19:00:00        0.000000        0.000000  \n",
      "2022-12-31 20:00:00        0.065994        0.000000  \n",
      "2022-12-31 21:00:00        0.057345        0.055771  \n",
      "2022-12-31 22:00:00        0.000000        0.000000  \n",
      "2022-12-31 23:00:00        0.065994        0.014507  \n",
      "\n",
      "[26304 rows x 10 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>1510H084 Water Level</th>\n",
       "      <th>1510H076 Water Level</th>\n",
       "      <th>1510H071 Water Level</th>\n",
       "      <th>1510H057 Water Level</th>\n",
       "      <th>19774 Rainfall</th>\n",
       "      <th>20016 Rainfall</th>\n",
       "      <th>19606 Rainfall</th>\n",
       "      <th>19335 Rainfall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-01-01 00:00:00</th>\n",
       "      <td>2020/1/1</td>\n",
       "      <td>00:00</td>\n",
       "      <td>145.3</td>\n",
       "      <td>5.03</td>\n",
       "      <td>20.58</td>\n",
       "      <td>88.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 01:00:00</th>\n",
       "      <td>2020/1/1</td>\n",
       "      <td>01:00</td>\n",
       "      <td>145.3</td>\n",
       "      <td>5.11</td>\n",
       "      <td>20.80</td>\n",
       "      <td>88.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 02:00:00</th>\n",
       "      <td>2020/1/1</td>\n",
       "      <td>02:00</td>\n",
       "      <td>145.3</td>\n",
       "      <td>5.11</td>\n",
       "      <td>20.81</td>\n",
       "      <td>88.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 03:00:00</th>\n",
       "      <td>2020/1/1</td>\n",
       "      <td>03:00</td>\n",
       "      <td>145.3</td>\n",
       "      <td>5.11</td>\n",
       "      <td>20.80</td>\n",
       "      <td>88.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-01 04:00:00</th>\n",
       "      <td>2020/1/1</td>\n",
       "      <td>04:00</td>\n",
       "      <td>145.3</td>\n",
       "      <td>5.11</td>\n",
       "      <td>20.79</td>\n",
       "      <td>88.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Date   Time  1510H084 Water Level  \\\n",
       "Timestamp                                                    \n",
       "2020-01-01 00:00:00  2020/1/1  00:00                 145.3   \n",
       "2020-01-01 01:00:00  2020/1/1  01:00                 145.3   \n",
       "2020-01-01 02:00:00  2020/1/1  02:00                 145.3   \n",
       "2020-01-01 03:00:00  2020/1/1  03:00                 145.3   \n",
       "2020-01-01 04:00:00  2020/1/1  04:00                 145.3   \n",
       "\n",
       "                     1510H076 Water Level  1510H071 Water Level  \\\n",
       "Timestamp                                                         \n",
       "2020-01-01 00:00:00                  5.03                 20.58   \n",
       "2020-01-01 01:00:00                  5.11                 20.80   \n",
       "2020-01-01 02:00:00                  5.11                 20.81   \n",
       "2020-01-01 03:00:00                  5.11                 20.80   \n",
       "2020-01-01 04:00:00                  5.11                 20.79   \n",
       "\n",
       "                     1510H057 Water Level  19774 Rainfall  20016 Rainfall  \\\n",
       "Timestamp                                                                   \n",
       "2020-01-01 00:00:00                 88.47             0.0             0.0   \n",
       "2020-01-01 01:00:00                 88.79             0.0             0.0   \n",
       "2020-01-01 02:00:00                 88.78             0.0             0.0   \n",
       "2020-01-01 03:00:00                 88.84             0.0             0.0   \n",
       "2020-01-01 04:00:00                 88.81             0.0             0.0   \n",
       "\n",
       "                     19606 Rainfall  19335 Rainfall  \n",
       "Timestamp                                            \n",
       "2020-01-01 00:00:00             0.0        0.000000  \n",
       "2020-01-01 01:00:00             0.0        0.000000  \n",
       "2020-01-01 02:00:00             0.0        0.000000  \n",
       "2020-01-01 03:00:00             0.0        0.000000  \n",
       "2020-01-01 04:00:00             0.0        1.428012  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from scipy import stats\n",
    "from scipy.stats import norm,skew\n",
    "import warnings\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "# MinMaxScaler用於數據的歸一化\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 讀取數據\n",
    "\n",
    "def create_timestamp(data):\n",
    "    # 将\"Date\"和\"Time\"合併成時間戳記並設置為索引\n",
    "    data['Timestamp'] = pd.to_datetime(data['Date'] + ' ' + data['Time'])\n",
    "    data = data.set_index('Timestamp')\n",
    "    return data\n",
    "\n",
    "data_path = r'C:\\Users\\rex\\Desktop\\水位預測\\2\\總整理.csv'\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# 使用函數創建時間戳\n",
    "data = create_timestamp(data)\n",
    "print (data)\n",
    "data.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_excel_file = r\"C:\\Users\\rex\\Desktop\\水位預測\\2\\缺失值.xlsx\"\n",
    "\n",
    "rows_with_missing_values = data[data.isnull().any(axis=1)]\n",
    "\n",
    "rows_with_missing_values.to_excel(output_excel_file, index=False)\n",
    "\n",
    "print(\"已成功。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假設您的資料框架名稱為data\n",
    "# 列出所有您要增加特徵的欄位名稱\n",
    "columns_to_expand = [\n",
    "    \"1510H084 Water Level\",\n",
    "    \"1510H076 Water Level\",\n",
    "    \"1510H071 Water Level\",\n",
    "    \"1510H057 Water Level\",\n",
    "    \"19774 Rainfall\",\n",
    "    \"20016 Rainfall\",\n",
    "    \"19606 Rainfall\",\n",
    "    \"19335 Rainfall\"\n",
    "]\n",
    "\n",
    "# 增加_T+1到_T+48的特徵\n",
    "for col in columns_to_expand:\n",
    "    for t in range(1, 49):\n",
    "        new_col_name = f\"{col}_T+{t}\"\n",
    "        data[new_col_name] = data[col].shift(-t)\n",
    "\n",
    "# 增加_T-1到_T-48的特徵\n",
    "for col in columns_to_expand:\n",
    "    for t in range(1, 49):\n",
    "        new_col_name = f\"{col}_T-{t}\"\n",
    "        data[new_col_name] = data[col].shift(t)\n",
    "# 建立滑動窗口的平均水位和標準差\n",
    "window_size = 48 # 48小時\n",
    "\n",
    "for station in [\"1510H084\", \"1510H076\", \"1510H071\", \"1510H057\"]:\n",
    "    col = f\"{station} Water Level\"\n",
    "    data[f\"{col}_rolling_mean\"] = data[col].rolling(window_size).mean()     #過去48小時平均水位\n",
    "    data[f\"{col}_rolling_std\"] = data[col].rolling(window_size).std()       #過去48小時水位標準差\n",
    "data = data.dropna()\n",
    "\n",
    "data\n",
    "\n",
    "# data.to_excel(r'C:\\Users\\rex\\Desktop\\水位預測\\2\\總資料新增特徵.xlsx', index=False)\n",
    "\n",
    "# 對每個站點的水位差分\n",
    "for station in [\"1510H084\", \"1510H076\", \"1510H071\", \"1510H057\"]:\n",
    "    col = f\"{station} Water Level\"\n",
    "    data[f\"{col}_diff\"] = data[col].diff()                                  #前一小時水位差\n",
    "\n",
    "# 刪除包含NaN的行\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看數據維度\n",
    "print(data.shape)\n",
    "#看數據訊息\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 對每個站點的水位差分\n",
    "for station in [\"1510H084\", \"1510H076\", \"1510H071\", \"1510H057\"]:\n",
    "    col = f\"{station} Water Level\"\n",
    "    data[f\"{col}_diff\"] = data[col].diff()                                  #前一小時水位差\n",
    "\n",
    "# 刪除包含NaN的行\n",
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#看數據維度\n",
    "print(data.shape)\n",
    "#看數據訊息\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除不必要的列\n",
    "data = data.drop(['Date', 'Time'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10  # 選擇最相關的特徵數\n",
    "\n",
    "# 計算相關性\n",
    "corrmat = data.corr()\n",
    "\n",
    "for t in range(48, 49):\n",
    "    target = f\"1510H084 Water Level_T+{t}\"  # 將目標變數更改為相應的 T+n\n",
    "\n",
    "    # 獲取與目標變數相關性最高的k個特徵\n",
    "    topk = corrmat.nlargest(k, target)[target].index\n",
    "\n",
    "    # 計算這些特徵之間的相關性\n",
    "    cm = np.corrcoef(data[topk].values.T)\n",
    "\n",
    "    # 繪製熱圖\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.set(font_scale=1.25)\n",
    "    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=topk.values, xticklabels=topk.values)\n",
    "    plt.title(f\"Correlations for {target}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 分析目標變量的分布，計算均值與標準差\n",
    "# targets = [\"1510H084 Water Level\", \"1510H076 Water Level\", \"1510H071 Water Level\", \"1510H057 Water Level\"]\n",
    "\n",
    "# fig, axs = plt.subplots(2, 4, figsize=(24, 12))  # 創建一個包含8個子圖的圖形窗口\n",
    "\n",
    "# for i, target in enumerate(targets):\n",
    "    \n",
    "#     # 繪製概率密度函數和核密度估計的圖\n",
    "#     sns.distplot(data[target], fit=norm, ax=axs[0, i])   # 將圖繪製在適當的子圖上\n",
    "    \n",
    "#     (mu, sigma) = norm.fit(data[target])   # 對變量進行最大似然估計\n",
    "#     print('\\nmu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n",
    "    \n",
    "#     axs[0, i].legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)], loc='best')\n",
    "#     axs[0, i].set_ylabel('Frequency')\n",
    "#     axs[0, i].set_title('{} distribution'.format(target))\n",
    "    \n",
    "#     # 繪製概率圖\n",
    "#     stats.probplot(data[target], plot=axs[1, i])   # 將圖繪製在適當的子圖上\n",
    "\n",
    "# plt.tight_layout()  # 自動調整子圖的佈局，使之填滿整個圖形窗口\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets = ['1510H084 Water Level', '1510H076 Water Level', '1510H071 Water Level', '1510H057 Water Level']\n",
    "\n",
    "# # 僅保留數據集中的數值型列\n",
    "# numeric_data = data.select_dtypes(include=[np.number])\n",
    "\n",
    "# k = 15\n",
    "# corrmat = numeric_data.corr()\n",
    "# # 選擇與目標變數相關性最高的特徵\n",
    "# top_corr_features = []\n",
    "# for target in targets:\n",
    "#     top_corr = corrmat[target].nlargest(k).index\n",
    "#     top_corr_features.extend(top_corr)\n",
    "\n",
    "# # 移除重複的特徵\n",
    "# top_corr_features = list(dict.fromkeys(top_corr_features))\n",
    "\n",
    "# # 將目標變數移到列表前端\n",
    "# for target in reversed(targets):\n",
    "#     top_corr_features.remove(target)\n",
    "#     top_corr_features.insert(0, target)\n",
    "\n",
    "# cm = np.corrcoef(numeric_data[top_corr_features].values.T)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# sns.set(font_scale=1.25)\n",
    "# hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.3f', annot_kws={'size':10},\n",
    "#             yticklabels=top_corr_features, xticklabels=top_corr_features, cmap='RdYlBu_r', vmin=-0.2, vmax=1.0)\n",
    "# plt.title(f\"Top {k} Correlations with Targets\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 歸一化數據 X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0)) 最小最大歸一化\n",
    "scalers = {}\n",
    "for i in data.columns:\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    s_s = scaler.fit_transform(data[i].values.reshape(-1,1))\n",
    "    s_s = np.reshape(s_s, len(s_s))\n",
    "    scalers['scaler_'+ i] = scaler\n",
    "    data[i] = s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#導入\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold,cross_val_score,train_test_split,cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from tensorflow.keras.layers import TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定義滑動窗口，窗口由 time_steps 參數控制\n",
    "def create_dataset(X, y, time_steps=1):         #   X 和 y，分別代表特徵和目標變量。time_steps 參數則表示滑動窗口的大小。\n",
    "    Xs, ys = [], []                             #   創建兩個空的列表 Xs 和 ys\n",
    "    for i in range(len(X) - time_steps):        #從第一個時間點開始，一直到可以形成最後一個完整的滑動窗口的位置。\n",
    "        v = X.iloc[i:(i + time_steps)].values   #選取一個時間窗口內的數據。第 i 時間點開始，包含了接下來的 time_steps 個時間點的數據。\n",
    "        Xs.append(v)                            #將這個時間窗口的數據添加到 Xs 列表中。\n",
    "        ys.append(y.iloc[i + time_steps])       #將目標變量在該窗口之後的第一個值添加到 ys 列表中。這個值是與前面時間窗口的 X 對應的 y。\n",
    "    return np.array(Xs), np.array(ys)           #將 Xs 和 ys 轉換為 numpy 數組並返回。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Flatten' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m     47\u001b[0m model\u001b[39m.\u001b[39madd(Conv1D(filters\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, input_shape\u001b[39m=\u001b[39m(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], X_train\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])))\n\u001b[1;32m---> 48\u001b[0m model\u001b[39m.\u001b[39madd(TimeDistributed(Flatten()))\n\u001b[0;32m     49\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(\u001b[39m50\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtanh\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     50\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))                 \u001b[39m# 輸出層的神經元數量為1，因為是針對單個目標變量進行預測\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Flatten' is not defined"
     ]
    }
   ],
   "source": [
    "# 列出目標水位列\n",
    "target_columns = [\n",
    "    \"1510H084 Water Level\",\n",
    "    \"1510H076 Water Level\",\n",
    "    \"1510H071 Water Level\",\n",
    "    \"1510H057 Water Level\"\n",
    "]\n",
    "\n",
    "# 1. 增加目標列：T+1到T+48的目標水位\n",
    "for target_col in target_columns:\n",
    "    for t in range(1, 49):\n",
    "        target = f'{target_col}_target_{t}'\n",
    "        data[target] = data[target_col].shift(-t)\n",
    "        \n",
    "        # 2. 刪除T+1到T+48的特徵\n",
    "        for col in columns_to_expand:\n",
    "            if f\"{col}_T+{t}\" in data.columns:\n",
    "                data = data.drop(columns=[f\"{col}_T+{t}\"])\n",
    "\n",
    "# 移除含有 NaN 的行\n",
    "data = data.dropna()\n",
    "\n",
    "# 3. 切分數據集\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data = data[:train_size]\n",
    "test_data = data[train_size:]\n",
    "\n",
    "# 進一步切分訓練集和驗證集\n",
    "val_size = int(len(train_data) * 0.1)\n",
    "train_data, val_data = train_data[:-val_size], train_data[-val_size:]\n",
    "\n",
    "# 定義時間步長\n",
    "time_steps = 48\n",
    "\n",
    "# 對於每一個目標，進行一次以上的過程\n",
    "for target_col in target_columns:\n",
    "    for t in range(1, 49):\n",
    "        target = f'{target_col}_target_{t}'\n",
    "        \n",
    "        # 切分訓練集、驗證集與測試集\n",
    "        X_train, y_train = create_dataset(train_data, train_data[target], time_steps)\n",
    "        X_val, y_val = create_dataset(val_data, val_data[target], time_steps)\n",
    "        X_test, y_test = create_dataset(test_data, test_data[target], time_steps)\n",
    "        \n",
    "        # 4. 訓練模型並進行預測\n",
    "        model = Sequential()\n",
    "        model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(50, activation='tanh'))\n",
    "        model.add(Dense(1))                 # 輸出層的神經元數量為1，因為是針對單個目標變量進行預測\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            'model-{epoch:03d}.h5',         # 目標文件的名稱格式\n",
    "            monitor='val_loss',             # 要監視的值\n",
    "            verbose=0,                      # 日誌模式\n",
    "            save_best_only=True,            # 是否只保存最好的epoch\n",
    "            mode='auto'                     # 如果monitor選項是'val_loss'，那麼模式應該是'min'。如果monitor選項是'val_acc'，那麼模式應該是'max'\n",
    "        )\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=15,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val, y_val),\n",
    "            verbose=1,\n",
    "            shuffle=False,\n",
    "            callbacks=[early_stopping, checkpoint]  # 添加回調列表\n",
    "        )\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 5. 評估模型\n",
    "        y_pred = scalers['scaler_' + target].inverse_transform(y_pred).flatten()\n",
    "        y_test = scalers['scaler_' + target].inverse_transform(y_test).flatten()\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        print(f'Target: {target}, r2: {r2}, mse: {mse}, mae: {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TimeSeriesSplit交叉驗證\n",
    "# n_splits = 5\n",
    "\n",
    "# # RMSE\n",
    "# def rmsle_cv(model, X, y):\n",
    "#     tss = TimeSeriesSplit(n_splits=n_splits)\n",
    "#     rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=tss))\n",
    "#     return rmse\n",
    "\n",
    "# # MAE\n",
    "# def mae_cv(model, X, y):\n",
    "#     tss = TimeSeriesSplit(n_splits=n_splits)\n",
    "#     mae = -cross_val_score(model, X, y, scoring=\"neg_mean_absolute_error\", cv=tss)\n",
    "#     return mae\n",
    "\n",
    "# # R-squared\n",
    "# def r2_cv(model, X, y):\n",
    "#     tss = TimeSeriesSplit(n_splits=n_splits)\n",
    "#     r2 = cross_val_score(model, X, y, scoring=\"r2\", cv=tss)\n",
    "#     return r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 用來儲存模型的字典\n",
    "# models_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for target_name, target in zip([\"1510H084 Water Level\", \"1510H076 Water Level\", \"1510H071 Water Level\", \"1510H057 Water Level\"], [target_1510H084, target_1510H076, target_1510H071, target_1510H057]):\n",
    "#     print(\"Target:\", target_name)\n",
    "#     common_index = data.index.intersection(target.index)\n",
    "#     X = data.loc[common_index, features]  # 只選取兩個資料集共同的時間戳記和特徵\n",
    "#     y_selected = target.loc[common_index]  # 只選取兩個資料集共同的時間戳記和目標變量\n",
    "\n",
    "#     # 使用時間序列的方式拆分訓練集和驗證集\n",
    "#     train_size = int(len(X) * 0.8)\n",
    "#     X_train, X_valid = X.iloc[:train_size], X.iloc[train_size:]\n",
    "#     y_train, y_valid = y_selected.iloc[:train_size], y_selected.iloc[train_size:]\n",
    "\n",
    "    \n",
    "#     # Lasso\n",
    "#     lasso = make_pipeline(RobustScaler(), Lasso(alpha=0.0005, random_state=1))\n",
    "#     lasso.fit(X_train, y_train)\n",
    "    \n",
    "#     # 在驗證集上進行預測並評估性能\n",
    "#     y_pred = lasso.predict(X_valid)\n",
    "    \n",
    "#     # 更改評估函數，使之適用於驗證集\n",
    "#     mae = mae_cv(lasso, X_train, y_train)\n",
    "    \n",
    "#     rmse = rmsle_cv(lasso, X_train, y_train)\n",
    "    \n",
    "#     r2 = r2_cv(lasso, X_train, y_train)\n",
    "\n",
    "#     print(\"\\nLasso MAE score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n",
    "    \n",
    "#     print(\"\\nLasso RMSE score: {:.4f} ({:.4f})\\n\".format(rmse.mean(), rmse.std()))\n",
    "    \n",
    "#     print(\"\\nLasso R^2 score: {:.4f} ({:.4f})\\n\".format(r2.mean(), r2.std()))\n",
    "#     models_dict[target_name + '_lasso'] = lasso\n",
    "    \n",
    "    \n",
    "#     #ENet\n",
    "#     ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "#     ENet.fit(X_train, y_train)\n",
    "#     mae = mae_cv(ENet, X_train, y_train)\n",
    "#     rmse = rmsle_cv(ENet, X_train, y_train)\n",
    "#     r2 = r2_cv(ENet, X_train, y_train)\n",
    "#     print(\"\\nElasticNet MAE score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n",
    "#     print(\"\\nElasticNet RMSE score: {:.4f} ({:.4f})\\n\".format(rmse.mean(), rmse.std()))\n",
    "#     print(\"\\nElasticNet R^2 score: {:.4f} ({:.4f})\\n\".format(r2.mean(), r2.std()))\n",
    "#     models_dict[target_name + '_ENet'] = ENet\n",
    "    \n",
    "#     #KRR\n",
    "#     KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree= 2,coef0=2.5)\n",
    "#     KRR.fit(X_train, y_train)\n",
    "#     mae = mae_cv(KRR, X_train, y_train)\n",
    "#     rmse = rmsle_cv(KRR, X_train, y_train)\n",
    "#     r2 = r2_cv(KRR, X_train, y_train)\n",
    "#     print(\"\\nKernel Ridge RMSE score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n",
    "#     print(\"\\nKernel Ridge RMSE score: {:.4f} ({:.4f})\\n\".format(rmse.mean(), rmse.std()))\n",
    "#     print(\"\\nKernel Ridge R^2 score: {:.4f} ({:.4f})\\n\".format(r2.mean(), r2.std()))\n",
    "#     models_dict[target_name + '_KRR'] = KRR\n",
    "    \n",
    "#     #梯度提升\n",
    "#     GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "#                                     max_depth=4, max_features='sqrt',\n",
    "#                                     min_samples_leaf=15, min_samples_split=10,\n",
    "#                                     loss='huber', random_state=5)\n",
    "#     GBoost.fit(X_train, y_train)\n",
    "#     mae = mae_cv(GBoost, X_train, y_train)\n",
    "#     rmse = rmsle_cv(GBoost, X_train, y_train)\n",
    "#     r2 = r2_cv(GBoost, X_train, y_train)\n",
    "#     print(\"\\nGradient Boosting MAE score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n",
    "#     print(\"\\nGradient Boosting RMSE score: {:.4f} ({:.4f})\\n\".format(rmse.mean(), rmse.std()))\n",
    "#     print(\"\\nGradient Boosting R^2 score: {:.4f} ({:.4f})\\n\".format(r2.mean(), r2.std()))\n",
    "#     models_dict[target_name + '_GBoost'] = GBoost\n",
    "    \n",
    "#     #XGB\n",
    "#     model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.4608,     # colsamples_bytree 是列的採樣率    # gamma 是節點劃分所需的最小損失減少值\n",
    "#                              learning_rate=0.05, max_depth=3,               # learning_rate 是每次迭代的步長大小 # max_depth 是樹的最大深度\n",
    "#                              min_child_weight=1.7817,n_estimators=2200,     # min_child_weight 是子節點所需最小樣本數   # n_estimators 是樹的數量\n",
    "#                              subsample=0.5213,                              # subsample 是行的採樣率            \n",
    "#                              reg_alpha=0.4640, reg_lambda=0.8571,           # reg_alpha 和 reg_lambda 是 L1 和 L2 正則化項的權重\n",
    "#                              random_state=7, nthread=-1)                    # nthread 是 CPU 的使用數量\n",
    "#     #XGBoost\n",
    "#     model_xgb.fit(X_train, y_train)\n",
    "#     mae = mae_cv(model_xgb, X_train, y_train)\n",
    "#     rmse = rmsle_cv(model_xgb, X_train, y_train)\n",
    "#     r2 = r2_cv(model_xgb, X_train, y_train)\n",
    "#     print(\"\\nXgboost MAE score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n",
    "#     print(\"\\nXgboost RMSE score: {:.4f} ({:.4f})\\n\".format(rmse.mean(), rmse.std()))\n",
    "#     print(\"\\nXgboost R^2 score: {:.4f} ({:.4f})\\n\".format(r2.mean(), r2.std()))\n",
    "#     models_dict[target_name + '_xgb'] = model_xgb\n",
    "\n",
    "#     #lgb\n",
    "#     model_lgb = lgb.LGBMRegressor(objective='regression', num_leaves=28,\n",
    "#                                 learning_rate=0.020000000000000004, n_estimators=700,\n",
    "#                                 max_bin=40, subsample=0.7777777777777778, subsample_freq=3,\n",
    "#                                 colsample_bytree= 0.7777777777777778,\n",
    "#                                 min_child_samples=5, min_child_weight=11)\n",
    "\n",
    "#     model_lgb.fit(X_train, y_train)\n",
    "#     mae = mae_cv(model_lgb, X_train, y_train)\n",
    "#     rmse = score = rmsle_cv(model_lgb, X_train, y_train)\n",
    "#     r2 = r2_cv(model_lgb, X_train, y_train)\n",
    "#     print(\"\\nLGB MAE score: {:.4f} ({:.4f})\\n\".format(mae.mean(), mae.std()))\n",
    "#     print(\"\\nLGB RMSE score: {:.4f} ({:.4f})\\n\" .format(rmse.mean(), rmse.std()))\n",
    "#     print(\"\\nLGB R^2 score: {:.4f} ({:.4f})\\n\".format(r2.mean(), r2.std()))\n",
    "#     models_dict[target_name + '_lgb'] = model_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 假設目標變量的名稱列表\n",
    "# target_variables = [\"1510H084 Water Level\", \"1510H076 Water Level\", \"1510H071 Water Level\", \"1510H057 Water Level\"]\n",
    "\n",
    "# # 設置window_size為48\n",
    "# window_size = 48\n",
    "\n",
    "# # 用來儲存所有目標的預測結果\n",
    "# all_predictions = {}\n",
    "\n",
    "# # 逐一對每個目標變量進行預測\n",
    "# for target_variable in target_variables:\n",
    "#     # 準備預測的輸入數據\n",
    "#     input_data = data[features + [target_variable]].iloc[-window_size:]\n",
    "\n",
    "#     # 使用之前訓練的標準化器對輸入數據進行標準化\n",
    "#     for feature in features + [target_variable]:\n",
    "#         input_data[feature] = scalers['scaler_' + feature].transform(input_data[feature].values.reshape(-1, 1))\n",
    "\n",
    "#     # 使用訓練好的 Lasso 模型對未來的 48 個時間步進行預測\n",
    "#     # 假設 Lasso 模型存儲在 'models_dict' 字典中\n",
    "#     lasso_model = models_dict[target_variable + '_ENet']\n",
    "#     predictions = lasso_model.predict(input_data[features])\n",
    "\n",
    "#     # 將預測結果反標準化得到實際水位值\n",
    "#     predictions = scalers['scaler_' + target_variable].inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "#     # 儲存該目標的預測結果\n",
    "#     all_predictions[target_variable] = predictions\n",
    "\n",
    "# # all_predictions 包含了所有目標的預測結果，每個目標都有未來 48 個時間步的水位預測值（T+1 到 T+48）\n",
    "# # 可以透過 all_predictions[target_variable] 獲得特定目標的預測結果\n",
    "# print(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# for target_name, target in zip([\"1510H084 Water Level\", \"1510H076 Water Level\", \"1510H071 Water Level\", \"1510H057 Water Level\"], [target_1510H084, target_1510H076, target_1510H071, target_1510H057]):\n",
    "#     print(\"Target:\", target_name)\n",
    "#     common_index = data.index.intersection(target.index)\n",
    "#     X = data.loc[common_index, features]\n",
    "#     y_selected = target.loc[common_index]\n",
    "\n",
    "#     # 使用時間序列的方式拆分訓練集和驗證集\n",
    "#     train_size = int(len(X) * 0.8)\n",
    "#     X_train, X_valid = X.iloc[:train_size], X.iloc[train_size:]\n",
    "#     y_train, y_valid = y_selected.iloc[:train_size], y_selected.iloc[train_size:]\n",
    "\n",
    "#     # Lasso (你可以在迴圈中添加其他模型)\n",
    "#     lasso_model = models_dict[target_name + '_lasso']\n",
    "\n",
    "#     # 使用預測數據繪圖\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "    \n",
    "#     # 1. 準備預測的輸入數據\n",
    "#     target_variable = target_name\n",
    "#     input_data = X_valid.iloc[-window_size:]\n",
    "\n",
    "#     # 2. 使用之前訓練的標準化器對輸入數據進行標準化\n",
    "#     for feature in features:\n",
    "#         input_data[feature] = scalers['scaler_' + feature].transform(input_data[feature].values.reshape(-1, 1))\n",
    "\n",
    "#     # 3. 使用訓練好的 Lasso 模型對未來的 48 個時間步進行預測\n",
    "#     predictions = lasso_model.predict(input_data)\n",
    "\n",
    "#     # 將預測結果反標準化得到實際水位值\n",
    "#     predictions = scalers['scaler_' + target_variable].inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "#     # 'predictions' 現在包含未來 48 個時間步的水位預測值（T+1 到 T+48）\n",
    "#     forecast_index = pd.date_range(start=y_valid.index[-48], periods=window_size, freq=y_valid.index.inferred_freq)\n",
    "#     plt.plot(forecast_index, predictions, label='Predict', color='red')\n",
    "#     plt.plot(forecast_index, y_valid.values[-48:], label='True', color='blue')  # 只顯示未來 48 小時的真實值\n",
    "\n",
    "#     plt.xlabel('Timestamp')\n",
    "#     plt.ylabel(target_name)\n",
    "#     plt.title('True and Predicted Values over Time Steps for Target: ' + target_name)\n",
    "#     plt.legend()\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_variable = '1510H084 Water Level'\n",
    "# input_data = data[features + [target_variable]].iloc[-window_size:]\n",
    "\n",
    "# # 2. 使用之前訓練的標準化器對輸入數據進行標準化\n",
    "# for feature in features + [target_variable]:\n",
    "#     input_data[feature] = scalers['scaler_' + feature].transform(input_data[feature].values.reshape(-1, 1))\n",
    "\n",
    "# # 3. 使用訓練好的 Lasso 模型對未來的 48 個時間步進行預測\n",
    "# # 假設 Lasso 模型存儲在 'models_dict' 字典中\n",
    "# lasso_model = models_dict[target_variable + '_lasso']\n",
    "# predictions = lasso_model.predict(input_data[features])\n",
    "\n",
    "# # 將預測結果反標準化得到實際水位值\n",
    "# predictions = scalers['scaler_' + target_variable].inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "# # 'predictions' 現在包含未來 48 個時間步的水位預測值（T+1 到 T+48）\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install statsmodels\n",
    "# from statsmodels.graphics.tsaplots import plot_acf\n",
    "# # Define the list of columns to analyze\n",
    "# columns_to_analyze = [\"1510H084 Water Level\", \"1510H076 Water Level\", \"1510H071 Water Level\", \"1510H057 Water Level\", \"19774 Rainfall\", \"20016 Rainfall\", \"19606 Rainfall\", \"19335 Rainfall\"]\n",
    "\n",
    "# # Create a figure and axes\n",
    "# fig, axs = plt.subplots(len(columns_to_analyze), figsize=(10, 20))\n",
    "\n",
    "# # Generate the autocorrelation plot for each column\n",
    "# for ax, column in zip(axs, columns_to_analyze):\n",
    "#     plot_acf(data[column], ax=ax, lags=48, title=f'Autocorrelation of {column}')\n",
    "\n",
    "# # Display the plot\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_cols = [\"1510H084 Water Level\", \"1510H076 Water Level\", \"1510H071 Water Level\", \"1510H057 Water Level\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from math import sqrt\n",
    "\n",
    "# # 切分訓練集與測試集\n",
    "# train_size = int(len(data) * 0.8)\n",
    "# train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# def create_dataset(X, y, time_steps=1):\n",
    "#     Xs, ys = [], []\n",
    "#     for i in range(len(X) - time_steps):\n",
    "#         v = X.iloc[i:(i + time_steps)].values\n",
    "#         Xs.append(v)\n",
    "#         ys.append(y.iloc[i + time_steps])\n",
    "#     return np.array(Xs), np.array(ys)\n",
    "\n",
    "# # 創建輸入序列和目標序列\n",
    "# time_steps = 48\n",
    "# X_train, y_train = create_dataset(train, train[target_cols], time_steps)\n",
    "# X_test, y_test = create_dataset(test, test[target_cols], time_steps)\n",
    "\n",
    "# # 定義LSTM模型\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(150, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(150, activation='tanh'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(len(target_cols)))  # 輸出層的神經元數量應與目標變量數量相同\n",
    "\n",
    "# # 調整學習率\n",
    "# learning_rate = 0.01\n",
    "# optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# # 編譯模型\n",
    "# model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "# # 定義早停\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5)  \n",
    "\n",
    "# # 訓練模型\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=20,  \n",
    "#     batch_size=64,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1,\n",
    "#     shuffle=False,\n",
    "#     callbacks=[early_stopping]  \n",
    "# )\n",
    "\n",
    "# # 進行預測\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # 將預測值和實際值的縮放反轉回來\n",
    "# for i in range(len(target_cols)):\n",
    "#     y_pred[:, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_pred[:, i].reshape(-1, 1)).flatten()\n",
    "#     y_test[:, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_test[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# # 計算R^2 score\n",
    "# for i in range(len(target_cols)):\n",
    "#     r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
    "#     print(f'R^2 score for {target_cols[i]}: {r2}')\n",
    "# # 計算RMSE\n",
    "# for i in range(len(target_cols)):\n",
    "#     rmse = sqrt(mean_squared_error(y_test[:, i], y_pred[:, i]))\n",
    "#     print(f'RMSE for {target_cols[i]}: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Conv1D, LSTM, Dense, Dropout, Flatten, TimeDistributed\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# from math import sqrt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 切分訓練集與測試集\n",
    "# train_size = int(len(data) * 0.8)\n",
    "# train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# def create_dataset(X, y, time_steps=1, future_steps=1):\n",
    "#     Xs, ys = [], []\n",
    "#     for i in range(len(X) - time_steps - future_steps + 1):\n",
    "#         v = X.iloc[i:(i + time_steps)].values\n",
    "#         Xs.append(v)\n",
    "#         ys.append(y.iloc[i + time_steps: i + time_steps + future_steps].values)\n",
    "#     return np.array(Xs), np.array(ys)\n",
    "\n",
    "# # 創建輸入序列和目標序列，設定 future_steps=48\n",
    "# time_steps = 48\n",
    "# future_steps = 48  # 設定未來的時間步長\n",
    "# X_train, y_train = create_dataset(train, train[target_cols], time_steps, future_steps)\n",
    "# X_test, y_test = create_dataset(test, test[target_cols], time_steps, future_steps)\n",
    "\n",
    "# # y_train 和 y_test 需要從二維轉為三維形狀\n",
    "# y_train = y_train.reshape((y_train.shape[0], future_steps, len(target_cols)))\n",
    "# y_test = y_test.reshape((y_test.shape[0], future_steps, len(target_cols)))\n",
    "\n",
    "# # 定義LSTM模型\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(150, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(LSTM(150, activation='tanh', return_sequences=True))  # 返回序列\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(TimeDistributed(Dense(len(target_cols))))  # TimeDistributed 層可以對每個時間步長的輸出獨立應用全連接層\n",
    "\n",
    "# # 調整學習率\n",
    "# learning_rate = 0.01\n",
    "# optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# # 編譯模型\n",
    "# model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "\n",
    "# # 定義早停\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5)  \n",
    "\n",
    "# # 訓練模型\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=20,  \n",
    "#     batch_size=64,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1,\n",
    "#     shuffle=False,\n",
    "#     callbacks=[early_stopping]  \n",
    "# )\n",
    "\n",
    "# # 進行預測\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# for i in range(len(target_cols)):\n",
    "#     for j in range(future_steps):\n",
    "#         y_pred[:, j, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_pred[:, j, i].reshape(-1, 1)).flatten()\n",
    "#         y_test[:, j, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_test[:, j, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# # 計算 R^2 score 和 RMSE\n",
    "# for i in range(len(target_cols)):\n",
    "#     for j in range(future_steps):\n",
    "#         r2 = r2_score(y_test[:, j, i], y_pred[:, j, i])\n",
    "#         print(f'R^2 score for {target_cols[i]} at T+{j+1}: {r2}')\n",
    "#         rmse = sqrt(mean_squared_error(y_test[:, j, i], y_pred[:, j, i]))\n",
    "#         print(f'RMSE for {target_cols[i]} at T+{j+1}: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Flatten, TimeDistributed\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "#設置隨機種子實現可重現\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 切分訓練集與測試集\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "        v = X.iloc[i:(i + time_steps)].values\n",
    "        Xs.append(v)\n",
    "        ys.append(y.iloc[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "# 創建輸入序列和目標序列\n",
    "time_steps = 48     #基於前48小時的時間點預測下一個時間點的值\n",
    "X_train, y_train = create_dataset(train, train[target_cols], time_steps)\n",
    "X_test, y_test = create_dataset(test, test[target_cols], time_steps)\n",
    "\n",
    "# 定義ConvLSTM模型\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, activation='tanh'))\n",
    "model.add(Dense(len(target_cols)))  # 輸出層的神經元數量應與目標變量數量相同\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 定義早停\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2)  # 當驗證集上的損失在 2 個 epoch 內沒有改善時，停止訓練\n",
    "\n",
    "# 訓練模型\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=15,\n",
    "    batch_size=32,\n",
    "    validation_split=0.1,\n",
    "    verbose=1,\n",
    "    shuffle=False,\n",
    "    callbacks=[early_stopping]  # 添加早停回調\n",
    ")\n",
    "\n",
    "# 保存模型\n",
    "model.save('model.h5')\n",
    "\n",
    "#保存權重\n",
    "weights = model.get_weights()\n",
    "model.save_weights('my_model_weights.h5')\n",
    "\n",
    "# 載入模型\n",
    "model = tf.keras.models.load_model('model.h5')  \n",
    "\n",
    "# 載入模型權重\n",
    "model.load_weights('my_model_weights.h5')\n",
    "\n",
    "# 進行預測\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 將預測值和實際值的縮放反轉回來\n",
    "for i in range(len(target_cols)):\n",
    "    y_pred[:, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_pred[:, i].reshape(-1, 1)).flatten()\n",
    "    y_test[:, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_test[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# 計算R^2 score\n",
    "for i in range(len(target_cols)):\n",
    "    r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
    "    print(f'R^2 score for {target_cols[i]}: {r2}')\n",
    "# 計算RMSE\n",
    "for i in range(len(target_cols)):\n",
    "    rmse = sqrt(mean_squared_error(y_test[:, i], y_pred[:, i]))\n",
    "    print(f'RMSE for {target_cols[i]}: {rmse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import RepeatVector\n",
    "# from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定義模型儲存的位置\n",
    "# filepath = \"best_model.hdf5\"\n",
    "\n",
    "# # 創建 ModelCheckpoint 回調\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # 切分訓練集與測試集\n",
    "# train_size = int(len(data) * 0.8)\n",
    "# train, test = data[:train_size], data[train_size:]\n",
    "\n",
    "# def create_dataset(X, y, time_steps=1, future_steps=1):  # 此處新增 future_steps 參數\n",
    "#     Xs, ys = [], []\n",
    "#     for i in range(len(X) - time_steps - future_steps + 1):  # 此處修正 range 的終止條件\n",
    "#         v = X.iloc[i:(i + time_steps)].values\n",
    "#         Xs.append(v)\n",
    "#         ys.append(y.iloc[i + time_steps: i + time_steps + future_steps].values)  # 此處修正目標值序列\n",
    "#     return np.array(Xs), np.array(ys)\n",
    "\n",
    "# # 創建輸入序列和目標序列，設定 future_steps=48\n",
    "# time_steps = 48\n",
    "# future_steps = 48  # 設定未來的時間步長\n",
    "# X_train, y_train = create_dataset(train, train[target_cols], time_steps, future_steps)\n",
    "# X_test, y_test = create_dataset(test, test[target_cols], time_steps, future_steps)\n",
    "\n",
    "# # 定義ConvLSTM模型\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "# model.add(TimeDistributed(Flatten()))\n",
    "# model.add(LSTM(50, activation='tanh', return_sequences=False))  \n",
    "# model.add(RepeatVector(future_steps))  \n",
    "# model.add(TimeDistributed(Dense(len(target_cols))))  \n",
    "\n",
    "# # 編譯模型\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# # 定義早停\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=2)  # 當驗證集上的損失在 2 個 epoch 內沒有改善時，停止訓練\n",
    "\n",
    "# # 訓練模型\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=15,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1,\n",
    "#     shuffle=False,\n",
    "#     callbacks=[early_stopping, checkpoint]  # 添加早停回調和儲存最佳模型回調\n",
    "# )\n",
    "\n",
    "# # 進行預測\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # 將預測值和實際值的縮放反轉回來\n",
    "# for i in range(len(target_cols)):\n",
    "#     for j in range(future_steps):\n",
    "#         y_pred[:, j, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_pred[:, j, i].reshape(-1, 1)).flatten()\n",
    "#         y_test[:, j, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_test[:, j, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# # 計算 R^2 score 和 RMSE\n",
    "# for i in range(len(target_cols)):\n",
    "#     for j in range(future_steps):\n",
    "#         r2 = r2_score(y_test[:, j, i], y_pred[:, j, i])\n",
    "#         print(f'R^2 score for {target_cols[i]} at T+{j+1}: {r2}')\n",
    "#         rmse = sqrt(mean_squared_error(y_test[:, j, i], y_pred[:, j, i]))\n",
    "#         print(f'RMSE for {target_cols[i]} at T+{j+1}: {rmse}')\n",
    "    \n",
    "# model.save('best_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 訓練結束後，載入最好的模型\n",
    "# best_model = load_model('best_model.hdf5')\n",
    "\n",
    "# # 進行預測\n",
    "# y_pred = best_model.predict(X_test)\n",
    "\n",
    "# # 將預測值和實際值的縮放反轉回來\n",
    "# for i in range(len(target_cols)):\n",
    "#     for j in range(future_steps):\n",
    "#         y_pred[:, j, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_pred[:, j, i].reshape(-1, 1)).flatten()\n",
    "#         y_test[:, j, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_test[:, j, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# # 計算 R^2 score 和 RMSE\n",
    "# for i in range(len(target_cols)):\n",
    "#     for j in range(future_steps):\n",
    "#         r2 = r2_score(y_test[:, j, i], y_pred[:, j, i])\n",
    "#         print(f'R^2 score for {target_cols[i]} at T+{j+1}: {r2}')\n",
    "#         rmse = sqrt(mean_squared_error(y_test[:, j, i], y_pred[:, j, i]))\n",
    "#         print(f'RMSE for {target_cols[i]} at T+{j+1}: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "# # 加載模型\n",
    "# model = load_model(r'C:\\Users\\rex\\Desktop\\git\\data-processing\\best_model.h5')\n",
    "\n",
    "# # 進行預測\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # 將預測值和實際值的縮放反轉回來\n",
    "# for i in range(len(target_cols)):\n",
    "#     y_pred[:, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_pred[:, i].reshape(-1, 1)).flatten()\n",
    "#     y_test[:, i] = scalers['scaler_' + target_cols[i]].inverse_transform(y_test[:, i].reshape(-1, 1)).flatten()\n",
    "\n",
    "# # 計算R^2 score\n",
    "# for i in range(len(target_cols)):\n",
    "#     r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
    "#     print(f'R^2 score for {target_cols[i]}: {r2}')\n",
    "# # 計算RMSE\n",
    "# for i in range(len(target_cols)):\n",
    "#     rmse = sqrt(mean_squared_error(y_test[:, i], y_pred[:, i]))\n",
    "#     print(f'RMSE for {target_cols[i]}: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定義模型儲存的位置\n",
    "# filepath=\"best_model.hdf5\"\n",
    "\n",
    "# # 定義模型儲存的規則\n",
    "# checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "# # 將模型儲存規則加入到callbacks list\n",
    "# callbacks_list = [early_stopping, checkpoint]\n",
    "\n",
    "# # 在模型訓練的函式中添加 callbacks 參數\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=15,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1,\n",
    "#     shuffle=False,\n",
    "#     callbacks=callbacks_list  # 添加早停回調和模型儲存規則\n",
    "# )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
